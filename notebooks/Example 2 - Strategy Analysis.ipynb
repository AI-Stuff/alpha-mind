{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PyFin.api import *\n",
    "from alphamind.api import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back test parameter settings\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2018-02-24'\n",
    "\n",
    "freq = '10b'\n",
    "industry_lower = 1.\n",
    "industry_upper = 1.\n",
    "neutralized_risk = industry_styles\n",
    "industry_name = 'sw_adj'\n",
    "industry_level = 1\n",
    "turn_over_target_base = 0.4\n",
    "benchmark_total_lower = 0.8\n",
    "benchmark_total_upper = 1.0\n",
    "batch = 0\n",
    "horizon = map_freq(freq)\n",
    "weight_gap = 0.01\n",
    "universe = Universe(\"custom\", ['zz800'])\n",
    "data_source = 'postgres+psycopg2://postgres:we083826@192.168.0.102/alpha'\n",
    "benchmark_code = 905\n",
    "offset = 1\n",
    "method = 'risk_neutral'\n",
    "target_vol = 0.05\n",
    "risk_model = 'short'\n",
    "\n",
    "if risk_model == 'day':\n",
    "    risk_model_name = 'd_srisk'\n",
    "elif risk_model == 'short':\n",
    "    risk_model_name = 's_srisk'\n",
    "else:\n",
    "    risk_model_name = 'l_srisk'\n",
    "\n",
    "executor = NaiveExecutor()\n",
    "ref_dates = makeSchedule(start_date, end_date, freq, 'china.sse')\n",
    "engine = SqlEngine(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_factors = {\n",
    "    'f01': LAST('ep_q'),\n",
    "    'f02': LAST('roe_q'),\n",
    "    'f03': LAST('market_confidence_25d'),\n",
    "    'f04': LAST('ILLIQUIDITY'),\n",
    "    'f05': LAST('cfinc1_q'),\n",
    "    'f06': LAST('CFO2EV'),\n",
    "    'f07': LAST('IVR'),\n",
    "    'f08': LAST('con_pe_rolling_order'),\n",
    "    'f09': LAST('con_pb_rolling_order'),\n",
    "}\n",
    "\n",
    "weights = dict(f01=1.,\n",
    "               f02=1.,\n",
    "               f03=0.25,\n",
    "               f04=0.25,\n",
    "               f05=0.25,\n",
    "               f06=0.25,\n",
    "               f07=0.25,\n",
    "               f08=-0.25,\n",
    "               f09=-0.25)\n",
    "\n",
    "alpha_model = ConstLinearModel(features=alpha_factors, weights=weights)\n",
    "\n",
    "def train_worker(ref_date):\n",
    "    data_meta = DataMeta(freq=freq,\n",
    "                         universe=universe,\n",
    "                         batch=batch,\n",
    "                         neutralized_risk=neutralized_risk,\n",
    "                         risk_model='short',\n",
    "                         pre_process=[winsorize_normal, standardize],\n",
    "                         post_process=[winsorize_normal, standardize],\n",
    "                         warm_start=0,\n",
    "                         data_source=data_source)\n",
    "    \n",
    "    return train_model(ref_date, alpha_model, data_meta)\n",
    "\n",
    "\n",
    "def predict_worker(params):\n",
    "    data_meta = DataMeta(freq=freq,\n",
    "                         universe=universe,\n",
    "                         batch=batch,\n",
    "                         neutralized_risk=neutralized_risk,\n",
    "                         risk_model='short',\n",
    "                         pre_process=[winsorize_normal, standardize],\n",
    "                         post_process=[winsorize_normal, standardize],\n",
    "                         warm_start=0,\n",
    "                         data_source=data_source)\n",
    "    ref_date, model = params\n",
    "    er = predict_by_model(ref_date, model, data_meta)\n",
    "    return er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# training / predict on dask executor\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client('192.168.0.102:8786')\n",
    "\n",
    "tasks = client.map(predict_worker, [(d.strftime('%Y-%m-%d'), alpha_model) for d in ref_dates], pure=False)\n",
    "predicts = client.gather(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebalance\n",
    "\n",
    "industry_names = industry_list(industry_name, industry_level)\n",
    "constraint_risk = ['SIZE', 'SIZENL', 'BETA']  + industry_names\n",
    "total_risk_names = constraint_risk + ['benchmark', 'total']\n",
    "all_styles = risk_styles + industry_styles + macro_styles\n",
    "\n",
    "b_type = []\n",
    "l_val = []\n",
    "u_val = []\n",
    "\n",
    "previous_pos = pd.DataFrame()\n",
    "rets = []\n",
    "turn_overs = []\n",
    "leverags = []\n",
    "\n",
    "for name in total_risk_names:\n",
    "    if name == 'benchmark':\n",
    "        b_type.append(BoundaryType.RELATIVE)\n",
    "        l_val.append(benchmark_total_lower)\n",
    "        u_val.append(benchmark_total_upper)\n",
    "    elif name in {'SIZE', 'SIZENL', 'BETA'}:\n",
    "        b_type.append(BoundaryType.ABSOLUTE)\n",
    "        l_val.append(0.0)\n",
    "        u_val.append(0.0)\n",
    "    else:\n",
    "        b_type.append(BoundaryType.RELATIVE)\n",
    "        l_val.append(industry_lower)\n",
    "        u_val.append(industry_upper)\n",
    "\n",
    "bounds = create_box_bounds(total_risk_names, b_type, l_val, u_val)\n",
    "\n",
    "industry_total = engine.fetch_industry_matrix_range(universe, dates=ref_dates, category=industry_name, level=industry_level)\n",
    "benchmark_total = engine.fetch_benchmark_range(dates=ref_dates, benchmark=benchmark_code)\n",
    "risk_cov_total, risk_exposure_total = engine.fetch_risk_model_range(universe, dates=ref_dates, risk_model=risk_model)\n",
    "\n",
    "for i, ref_date in enumerate(ref_dates):\n",
    "    ref_date = ref_date.strftime('%Y-%m-%d')\n",
    "    industry_matrix = industry_total[industry_total.trade_date == ref_date]\n",
    "    benchmark_w = benchmark_total[benchmark_total.trade_date == ref_date]\n",
    "    risk_exposure = risk_exposure_total[risk_exposure_total.trade_date == ref_date]\n",
    "    risk_cov = risk_cov_total[risk_cov_total.trade_date == ref_date]\n",
    "    \n",
    "    res = pd.merge(industry_matrix, benchmark_w, on=['code'], how='left').fillna(0.)\n",
    "    res = pd.merge(res, risk_exposure, on=['code'])\n",
    "    res = res.dropna()\n",
    "    codes = res.code.values.tolist()\n",
    "    \n",
    "    risk_exposure = res[all_styles].values\n",
    "    risk_cov = risk_cov[all_styles].values\n",
    "    special_risk = res[risk_model_name].values\n",
    "    sec_cov = risk_exposure @ risk_cov @ risk_exposure.T / 10000 + np.diag(special_risk ** 2) / 10000\n",
    "    \n",
    "    benchmark_w = res.weight.values\n",
    "    is_in_benchmark = (benchmark_w > 0.).astype(float).reshape((-1, 1))\n",
    "    \n",
    "    total_risk_exp = np.concatenate([res[constraint_risk].values.astype(float),\n",
    "                                     is_in_benchmark,\n",
    "                                     np.ones_like(is_in_benchmark)],\n",
    "                                    axis=1)\n",
    "    total_risk_exp = pd.DataFrame(total_risk_exp, columns=total_risk_names)\n",
    "    constraints = LinearConstraints(bounds, total_risk_exp, benchmark_w)\n",
    "    \n",
    "    lbound = np.maximum(0., benchmark_w - weight_gap)  # np.zeros(len(total_data))\n",
    "    ubound = weight_gap + benchmark_w\n",
    "    \n",
    "    if previous_pos.empty:\n",
    "        current_position = None\n",
    "        turn_over_target = None\n",
    "    else:\n",
    "        previous_pos.set_index('code', inplace=True)\n",
    "        remained_pos = previous_pos.loc[codes]\n",
    "\n",
    "        remained_pos.fillna(0., inplace=True)\n",
    "        turn_over_target = turn_over_target_base\n",
    "        current_position = remained_pos.weight.values\n",
    "        \n",
    "    er = predicts[i].loc[codes].values\n",
    "    \n",
    "    try:\n",
    "        alpha_logger.info('{0} partial re-balance: {1}'.format(ref_date, len(er)))\n",
    "        target_pos, _ = er_portfolio_analysis(er,\n",
    "                                              industry_matrix.industry_name.values,\n",
    "                                              None,\n",
    "                                              constraints,\n",
    "                                              False,\n",
    "                                              benchmark_w,\n",
    "                                              method=method,\n",
    "                                              turn_over_target=turn_over_target,\n",
    "                                              current_position=current_position,\n",
    "                                              lbound=lbound,\n",
    "                                              ubound=ubound,\n",
    "                                              target_vol=target_vol,\n",
    "                                              cov=sec_cov)\n",
    "    except ValueError:\n",
    "        alpha_logger.info('{0} full re-balance: {1}'.format(ref_date, len(er)))\n",
    "        target_pos, _ = er_portfolio_analysis(er,\n",
    "                                              industry_matrix.industry_name.values,\n",
    "                                              None,\n",
    "                                              constraints,\n",
    "                                              False,\n",
    "                                              benchmark_w,\n",
    "                                              method=method,\n",
    "                                              lbound=lbound,\n",
    "                                              ubound=ubound,\n",
    "                                              target_vol=target_vol,\n",
    "                                              cov=sec_co)\n",
    "        \n",
    "    target_pos['code'] = codes\n",
    "    turn_over, executed_pos = executor.execute(target_pos=target_pos)\n",
    "\n",
    "    executed_codes = executed_pos.code.tolist()\n",
    "    dx_returns = engine.fetch_dx_return(ref_date, executed_codes, horizon=horizon, offset=offset)\n",
    "    result = pd.merge(executed_pos, dx_returns, on=['code'])\n",
    "\n",
    "    leverage = result.weight.abs().sum()\n",
    "\n",
    "    ret = result.weight.values @ (np.exp(result.dx.values) - 1.)\n",
    "    rets.append(np.log(1. + ret))\n",
    "    executor.set_current(executed_pos)\n",
    "    turn_overs.append(turn_over)\n",
    "    leverags.append(leverage)\n",
    "\n",
    "    previous_pos = executed_pos\n",
    "    alpha_logger.info('{0} is finished'.format(ref_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_df = pd.DataFrame({'returns': rets, 'turn_over': turn_overs, 'leverage': leverags}, index=ref_dates)\n",
    "\n",
    "# index return\n",
    "index_return = engine.fetch_dx_return_index_range(benchmark_code, start_date, end_date, horizon=horizon,\n",
    "                                                  offset=offset).set_index('trade_date')\n",
    "ret_df['index'] = index_return['dx']\n",
    "\n",
    "ret_df.loc[advanceDateByCalendar('china.sse', ref_dates[-1], freq)] = 0.\n",
    "ret_df = ret_df.shift(1)\n",
    "ret_df.iloc[0] = 0.\n",
    "ret_df['tc_cost'] = ret_df.turn_over * 0.002\n",
    "ret_df['returns'] = ret_df['returns'] - ret_df['index'] * ret_df['leverage']\n",
    "\n",
    "ret_df[['returns', 'tc_cost']].cumsum().plot(figsize=(12, 6),\n",
    "                                             title='Fixed freq rebalanced: {0} with benchmark {1}'.format(freq, 905),\n",
    "                                             secondary_y='tc_cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tornado.application - ERROR - Exception in callback functools.partial(<function wrap.<locals>.null_wrapper at 0x000001C2002EDD90>, <tornado.concurrent.Future object at 0x000001C2054252E8>)\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\distributed\\comm\\core.py\", line 185, in connect\n",
      "    quiet_exceptions=EnvironmentError)\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\gen.py\", line 1055, in run\n",
      "    value = future.result()\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\concurrent.py\", line 238, in result\n",
      "    raise_exc_info(self._exc_info)\n",
      "  File \"<string>\", line 4, in raise_exc_info\n",
      "tornado.gen.TimeoutError: Timeout\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\ioloop.py\", line 605, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\ioloop.py\", line 626, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\concurrent.py\", line 238, in result\n",
      "    raise_exc_info(self._exc_info)\n",
      "  File \"<string>\", line 4, in raise_exc_info\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\gen.py\", line 1063, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\distributed\\client.py\", line 804, in _update_scheduler_info\n",
      "    self._scheduler_identity = yield self.scheduler.identity()\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\gen.py\", line 1055, in run\n",
      "    value = future.result()\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\concurrent.py\", line 238, in result\n",
      "    raise_exc_info(self._exc_info)\n",
      "  File \"<string>\", line 4, in raise_exc_info\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\gen.py\", line 1063, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\distributed\\core.py\", line 463, in send_recv_from_rpc\n",
      "    comm = yield self.live_comm()\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\gen.py\", line 1055, in run\n",
      "    value = future.result()\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\concurrent.py\", line 238, in result\n",
      "    raise_exc_info(self._exc_info)\n",
      "  File \"<string>\", line 4, in raise_exc_info\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\gen.py\", line 1063, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\distributed\\core.py\", line 439, in live_comm\n",
      "    connection_args=self.connection_args)\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\gen.py\", line 1055, in run\n",
      "    value = future.result()\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\concurrent.py\", line 238, in result\n",
      "    raise_exc_info(self._exc_info)\n",
      "  File \"<string>\", line 4, in raise_exc_info\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\tornado\\gen.py\", line 1063, in run\n",
      "    yielded = self.gen.throw(*exc_info)\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\distributed\\comm\\core.py\", line 194, in connect\n",
      "    _raise(error)\n",
      "  File \"D:\\ProgramData\\IntelPython3_2018\\lib\\site-packages\\distributed\\comm\\core.py\", line 177, in _raise\n",
      "    raise IOError(msg)\n",
      "OSError: Timed out trying to connect to 'tcp://192.168.0.102:8786' after 5 s: connect() didn't finish in time\n"
     ]
    }
   ],
   "source": [
    "ret_df[['returns', 'tc_cost']][-30:].cumsum().plot(figsize=(12, 6),\n",
    "                                             title='Fixed freq rebalanced: {0} with benchmark {1}'.format(freq, 905),\n",
    "                                             secondary_y='tc_cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
